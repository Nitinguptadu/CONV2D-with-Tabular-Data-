{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten, TimeDistributed, ConvLSTM2D, Reshape\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics as sm\n",
    "import keras\n",
    "\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  X379  \\\n",
       "0   0  130.81   k  v  at  a  d  u  j  o  ...     0     0     1     0     0   \n",
       "1   6   88.53   k  t  av  e  d  y  l  o  ...     1     0     0     0     0   \n",
       "2   7   76.26  az  w   n  c  d  x  j  x  ...     0     0     0     0     0   \n",
       "3   9   80.62  az  t   n  f  d  x  l  e  ...     0     0     0     0     0   \n",
       "4  13   78.02  az  v   n  f  d  h  d  n  ...     0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  data.drop([\"ID\",\"X0\",\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X8\" ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        y  X10  X11  X12  X13  X14  X15  X16  X17  X18  ...  X375  X376  X377  \\\n",
       "0  130.81    0    0    0    1    0    0    0    0    1  ...     0     0     1   \n",
       "1   88.53    0    0    0    0    0    0    0    0    1  ...     1     0     0   \n",
       "2   76.26    0    0    0    0    0    0    0    1    0  ...     0     0     0   \n",
       "3   80.62    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "4   78.02    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "\n",
       "   X378  X379  X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0  \n",
       "2     0     0     0     1     0     0     0  \n",
       "3     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 369 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 369)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>b</td>\n",
       "      <td>ai</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>as</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>j</td>\n",
       "      <td>j</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>az</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>z</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>w</td>\n",
       "      <td>s</td>\n",
       "      <td>as</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>i</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>8410</td>\n",
       "      <td>aj</td>\n",
       "      <td>h</td>\n",
       "      <td>as</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>aa</td>\n",
       "      <td>j</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>8411</td>\n",
       "      <td>t</td>\n",
       "      <td>aa</td>\n",
       "      <td>ai</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>aa</td>\n",
       "      <td>j</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>8413</td>\n",
       "      <td>y</td>\n",
       "      <td>v</td>\n",
       "      <td>as</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>aa</td>\n",
       "      <td>d</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>8414</td>\n",
       "      <td>ak</td>\n",
       "      <td>v</td>\n",
       "      <td>as</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>aa</td>\n",
       "      <td>c</td>\n",
       "      <td>q</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>8416</td>\n",
       "      <td>t</td>\n",
       "      <td>aa</td>\n",
       "      <td>ai</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>aa</td>\n",
       "      <td>g</td>\n",
       "      <td>r</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4209 rows × 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  X0  X1  X2 X3 X4  X5 X6 X8  X10  ...  X375  X376  X377  X378  \\\n",
       "0        1  az   v   n  f  d   t  a  w    0  ...     0     0     0     1   \n",
       "1        2   t   b  ai  a  d   b  g  y    0  ...     0     0     1     0   \n",
       "2        3  az   v  as  f  d   a  j  j    0  ...     0     0     0     1   \n",
       "3        4  az   l   n  f  d   z  l  n    0  ...     0     0     0     1   \n",
       "4        5   w   s  as  c  d   y  i  m    0  ...     1     0     0     0   \n",
       "...    ...  ..  ..  .. .. ..  .. .. ..  ...  ...   ...   ...   ...   ...   \n",
       "4204  8410  aj   h  as  f  d  aa  j  e    0  ...     0     0     0     0   \n",
       "4205  8411   t  aa  ai  d  d  aa  j  y    0  ...     0     1     0     0   \n",
       "4206  8413   y   v  as  f  d  aa  d  w    0  ...     0     0     0     0   \n",
       "4207  8414  ak   v  as  a  d  aa  c  q    0  ...     0     0     1     0   \n",
       "4208  8416   t  aa  ai  c  d  aa  g  r    0  ...     1     0     0     0   \n",
       "\n",
       "      X379  X380  X382  X383  X384  X385  \n",
       "0        0     0     0     0     0     0  \n",
       "1        0     0     0     0     0     0  \n",
       "2        0     0     0     0     0     0  \n",
       "3        0     0     0     0     0     0  \n",
       "4        0     0     0     0     0     0  \n",
       "...    ...   ...   ...   ...   ...   ...  \n",
       "4204     0     0     0     0     0     0  \n",
       "4205     0     0     0     0     0     0  \n",
       "4206     0     0     0     0     0     0  \n",
       "4207     0     0     0     0     0     0  \n",
       "4208     0     0     0     0     0     0  \n",
       "\n",
       "[4209 rows x 377 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest =  dtest.drop([\"ID\",\"X0\",\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X8\" ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 368 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X10  X11  X12  X13  X14  X15  X16  X17  X18  X19  ...  X375  X376  X377  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "1    0    0    0    0    0    0    0    0    0    1  ...     0     0     1   \n",
       "2    0    0    0    0    1    0    0    0    0    0  ...     0     0     0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "4    0    0    0    0    1    0    0    0    0    0  ...     1     0     0   \n",
       "\n",
       "   X378  X379  X380  X382  X383  X384  X385  \n",
       "0     1     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0  \n",
       "2     1     0     0     0     0     0     0  \n",
       "3     1     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 368 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 368)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data.values[0:3499,1:], data.values[0:3499, :1].ravel()\n",
    "X_valid, y_valid = data.values[3500:4208,1:], data.values[3500:4208, :1].ravel()\n",
    "X_test = dtest.values[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train---- (3499, 368)\n",
      "y_train---- (3499,)\n",
      "X_valid---- (708, 368)\n",
      "y_valid---- (708,)\n",
      "X_test----- (4209, 368)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train----\",X_train.shape)\n",
    "print(\"y_train----\",y_train.shape)      \n",
    "print(\"X_valid----\",X_valid.shape)\n",
    "print(\"y_valid----\",y_valid.shape)\n",
    "print(\"X_test-----\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130.81"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = min_max_scaler.fit_transform(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(pred, y_test):\n",
    "    evs = sm.explained_variance_score(y_test, pred)\n",
    "    me = sm.max_error(y_test, pred)\n",
    "    mae = sm.mean_absolute_error(y_test, pred)\n",
    "    mse = sm.mean_squared_error(y_test, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    #msle = sm.mean_squared_log_error(y_test, pred)\n",
    "    m_ae = sm.median_absolute_error(y_test, pred)\n",
    "    r2 = sm.r2_score(y_test, pred)\n",
    "    #mpd = sm.mean_poisson_deviance(y_test, pred)\n",
    "    #mgd = sm.mean_gamma_deviance(y_test, pred)\n",
    "    mape = mean_absolute_percentage_error(pred, y_test)\n",
    "    return({'Explained Variance Score': evs,\n",
    "            'Max Error': me,\n",
    "            'Mean Absolute Error': mae,\n",
    "            'Mean Squared Error': mse,\n",
    "            'Root Mean Squared Error': rmse,\n",
    "            #'Mean Squared Log Error': msle,\n",
    "            'Median Absolute Error': m_ae,\n",
    "            'R² Score': r2,\n",
    "            #'Mean Poisson Deviance': mpd,\n",
    "            #'Mean Gamma Deviance': mgd,\n",
    "            'Mean Absolute Percentage Error': mape\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsequences = 2\n",
    "timesteps = X_train.shape[1]//subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], subsequences, 1, timesteps, 1))\n",
    "X_valid = X_valid.reshape((X_valid.shape[0], subsequences, 1, timesteps, 1))\n",
    "X_test  = X_test.reshape((X_test.shape[0], subsequences, 1, timesteps, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3499, 2, 1, 184, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3499 samples, validate on 708 samples\n",
      "Epoch 1/500\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 10359.5778 - val_loss: 9932.8272\n",
      "Epoch 2/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 10330.7143 - val_loss: 9884.0376\n",
      "Epoch 3/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 10258.8020 - val_loss: 9777.1923\n",
      "Epoch 4/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 10111.2145 - val_loss: 9569.6503\n",
      "Epoch 5/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 9832.4343 - val_loss: 9187.3444\n",
      "Epoch 6/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 9327.5704 - val_loss: 8508.6025\n",
      "Epoch 7/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 8441.7870 - val_loss: 7337.4965\n",
      "Epoch 8/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 6937.0674 - val_loss: 5398.9394\n",
      "Epoch 9/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 4538.3370 - val_loss: 2557.7701\n",
      "Epoch 10/500\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1527.0002 - val_loss: 177.3773\n",
      "Epoch 11/500\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 454.9265 - val_loss: 838.4102\n",
      "Epoch 12/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 485.7102 - val_loss: 147.1038\n",
      "Epoch 13/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 227.6071 - val_loss: 230.5738\n",
      "Epoch 14/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 275.3749 - val_loss: 155.6051\n",
      "Epoch 15/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 184.2142 - val_loss: 161.7299\n",
      "Epoch 16/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 195.9591 - val_loss: 164.8549\n",
      "Epoch 17/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 180.3927 - val_loss: 138.2986\n",
      "Epoch 18/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 179.6160 - val_loss: 138.0437\n",
      "Epoch 19/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 177.3498 - val_loss: 140.2798\n",
      "Epoch 20/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 175.9974 - val_loss: 143.7221\n",
      "Epoch 21/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 175.3920 - val_loss: 139.3035\n",
      "Epoch 22/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 174.9011 - val_loss: 137.4291\n",
      "Epoch 23/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 174.5024 - val_loss: 138.8356\n",
      "Epoch 24/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 174.1231 - val_loss: 139.6155\n",
      "Epoch 25/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 173.8402 - val_loss: 137.6968\n",
      "Epoch 26/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 173.3863 - val_loss: 137.9131\n",
      "Epoch 27/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 173.0639 - val_loss: 137.5703\n",
      "Epoch 28/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 172.7466 - val_loss: 137.3651\n",
      "Epoch 29/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 172.4677 - val_loss: 137.4257\n",
      "Epoch 30/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 172.1348 - val_loss: 136.3749\n",
      "Epoch 31/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 171.7856 - val_loss: 136.6801\n",
      "Epoch 32/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 171.5169 - val_loss: 136.5625\n",
      "Epoch 33/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 171.1800 - val_loss: 135.8350\n",
      "Epoch 34/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 170.8886 - val_loss: 136.0233\n",
      "Epoch 35/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 170.5346 - val_loss: 135.1723\n",
      "Epoch 36/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 170.3464 - val_loss: 134.8862\n",
      "Epoch 37/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 170.0535 - val_loss: 135.6696\n",
      "Epoch 38/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 169.6466 - val_loss: 134.5661\n",
      "Epoch 39/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 169.3784 - val_loss: 134.1331\n",
      "Epoch 40/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 169.0855 - val_loss: 134.1296\n",
      "Epoch 41/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 168.7857 - val_loss: 134.0317\n",
      "Epoch 42/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 168.5107 - val_loss: 134.0830\n",
      "Epoch 43/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 168.2375 - val_loss: 133.3971\n",
      "Epoch 44/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 167.9472 - val_loss: 132.6903\n",
      "Epoch 45/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 167.6983 - val_loss: 133.4066\n",
      "Epoch 46/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 167.4396 - val_loss: 132.5228\n",
      "Epoch 47/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 167.1183 - val_loss: 132.9164\n",
      "Epoch 48/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 166.8614 - val_loss: 132.3841\n",
      "Epoch 49/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 166.6284 - val_loss: 132.1612\n",
      "Epoch 50/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 166.3976 - val_loss: 131.9569\n",
      "Epoch 51/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 166.2351 - val_loss: 132.1249\n",
      "Epoch 52/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 166.0298 - val_loss: 130.4809\n",
      "Epoch 53/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 165.5951 - val_loss: 132.3109\n",
      "Epoch 54/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 165.3530 - val_loss: 130.9220\n",
      "Epoch 55/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 165.0823 - val_loss: 130.3114\n",
      "Epoch 56/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 164.9239 - val_loss: 131.0220\n",
      "Epoch 57/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 164.5663 - val_loss: 130.0457\n",
      "Epoch 58/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 164.3829 - val_loss: 129.5378\n",
      "Epoch 59/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 164.2208 - val_loss: 130.9167\n",
      "Epoch 60/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 163.9262 - val_loss: 129.2722\n",
      "Epoch 61/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 163.6576 - val_loss: 129.4360\n",
      "Epoch 62/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 163.4702 - val_loss: 129.7509\n",
      "Epoch 63/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 163.3881 - val_loss: 128.4205\n",
      "Epoch 64/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 162.9780 - val_loss: 130.0436\n",
      "Epoch 65/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 162.7808 - val_loss: 128.5399\n",
      "Epoch 66/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 162.5450 - val_loss: 128.4459\n",
      "Epoch 67/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 162.3478 - val_loss: 128.1799\n",
      "Epoch 68/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 162.0728 - val_loss: 128.8759\n",
      "Epoch 69/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 161.9365 - val_loss: 127.4884\n",
      "Epoch 70/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 161.7024 - val_loss: 127.8312\n",
      "Epoch 71/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 161.4815 - val_loss: 128.2235\n",
      "Epoch 72/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 161.3684 - val_loss: 126.8066\n",
      "Epoch 73/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 161.0001 - val_loss: 127.6345\n",
      "Epoch 74/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 160.8576 - val_loss: 127.5484\n",
      "Epoch 75/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 10s 3ms/step - loss: 160.6477 - val_loss: 126.8497\n",
      "Epoch 76/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 160.5400 - val_loss: 126.6094\n",
      "Epoch 77/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 160.1961 - val_loss: 125.4206\n",
      "Epoch 78/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 160.0020 - val_loss: 126.9901\n",
      "Epoch 79/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 159.8956 - val_loss: 126.2280\n",
      "Epoch 80/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 159.6096 - val_loss: 126.2601\n",
      "Epoch 81/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 159.4248 - val_loss: 125.6298\n",
      "Epoch 82/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 159.1829 - val_loss: 125.1721\n",
      "Epoch 83/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 159.0043 - val_loss: 125.7331\n",
      "Epoch 84/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 159.1278 - val_loss: 125.2360\n",
      "Epoch 85/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 158.6117 - val_loss: 124.3186\n",
      "Epoch 86/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 158.5115 - val_loss: 125.4034\n",
      "Epoch 87/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 158.1981 - val_loss: 124.4624\n",
      "Epoch 88/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 158.0004 - val_loss: 124.2391\n",
      "Epoch 89/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 157.8534 - val_loss: 124.6863\n",
      "Epoch 90/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 157.6631 - val_loss: 123.9466\n",
      "Epoch 91/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 157.6169 - val_loss: 124.9188\n",
      "Epoch 92/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 157.2518 - val_loss: 123.6972\n",
      "Epoch 93/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 157.3176 - val_loss: 122.7804\n",
      "Epoch 94/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 157.1396 - val_loss: 125.3240\n",
      "Epoch 95/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 156.9520 - val_loss: 121.9355\n",
      "Epoch 96/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 156.6103 - val_loss: 124.3423\n",
      "Epoch 97/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 156.6617 - val_loss: 122.1565\n",
      "Epoch 98/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 156.1374 - val_loss: 123.6893\n",
      "Epoch 99/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 156.0754 - val_loss: 122.0377\n",
      "Epoch 100/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 155.6511 - val_loss: 122.9121\n",
      "Epoch 101/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 155.4688 - val_loss: 122.0930\n",
      "Epoch 102/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 155.2296 - val_loss: 121.3198\n",
      "Epoch 103/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 155.1047 - val_loss: 121.4128\n",
      "Epoch 104/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 154.8527 - val_loss: 122.0480\n",
      "Epoch 105/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 154.6340 - val_loss: 121.0020\n",
      "Epoch 106/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 154.4506 - val_loss: 121.2107\n",
      "Epoch 107/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 154.2594 - val_loss: 121.2057\n",
      "Epoch 108/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 154.1738 - val_loss: 120.6363\n",
      "Epoch 109/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 153.8089 - val_loss: 121.3006\n",
      "Epoch 110/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 153.6574 - val_loss: 120.2479\n",
      "Epoch 111/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 153.4389 - val_loss: 119.0561\n",
      "Epoch 112/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 153.1694 - val_loss: 121.1234\n",
      "Epoch 113/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 153.0387 - val_loss: 119.1951\n",
      "Epoch 114/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 152.8768 - val_loss: 120.0452\n",
      "Epoch 115/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 152.8632 - val_loss: 119.6141\n",
      "Epoch 116/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 152.7461 - val_loss: 117.7774\n",
      "Epoch 117/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 152.3580 - val_loss: 120.4917\n",
      "Epoch 118/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 151.8060 - val_loss: 117.5215\n",
      "Epoch 119/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 151.7924 - val_loss: 119.2791\n",
      "Epoch 120/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 151.4140 - val_loss: 117.3657\n",
      "Epoch 121/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 151.0527 - val_loss: 118.6973\n",
      "Epoch 122/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 150.9073 - val_loss: 117.2117\n",
      "Epoch 123/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 150.5877 - val_loss: 117.5536\n",
      "Epoch 124/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 150.4273 - val_loss: 116.8220\n",
      "Epoch 125/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 150.0939 - val_loss: 116.2392\n",
      "Epoch 126/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 149.9249 - val_loss: 117.2216\n",
      "Epoch 127/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 149.6045 - val_loss: 115.4136\n",
      "Epoch 128/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 149.4673 - val_loss: 116.6560\n",
      "Epoch 129/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 149.0129 - val_loss: 114.8598\n",
      "Epoch 130/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 148.8211 - val_loss: 115.7469\n",
      "Epoch 131/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 148.4647 - val_loss: 115.2293\n",
      "Epoch 132/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 148.1567 - val_loss: 115.1159\n",
      "Epoch 133/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 147.9227 - val_loss: 114.5312\n",
      "Epoch 134/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 147.7019 - val_loss: 114.4051\n",
      "Epoch 135/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 147.6949 - val_loss: 113.9068\n",
      "Epoch 136/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 147.1481 - val_loss: 113.9313\n",
      "Epoch 137/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 146.7426 - val_loss: 113.1450\n",
      "Epoch 138/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 146.3710 - val_loss: 113.8876\n",
      "Epoch 139/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 146.3944 - val_loss: 112.0884\n",
      "Epoch 140/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 146.3144 - val_loss: 113.4049\n",
      "Epoch 141/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 145.6583 - val_loss: 111.2945\n",
      "Epoch 142/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 144.9561 - val_loss: 113.3637\n",
      "Epoch 143/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 145.0401 - val_loss: 110.1473\n",
      "Epoch 144/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 144.7816 - val_loss: 111.6538\n",
      "Epoch 145/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 143.8500 - val_loss: 109.4736\n",
      "Epoch 146/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 143.5740 - val_loss: 111.4846\n",
      "Epoch 147/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 144.0998 - val_loss: 110.1105\n",
      "Epoch 148/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 143.1245 - val_loss: 108.1855\n",
      "Epoch 149/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 142.7325 - val_loss: 109.1417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 142.5467 - val_loss: 106.0977\n",
      "Epoch 151/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 141.3936 - val_loss: 108.6523\n",
      "Epoch 152/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 140.3931 - val_loss: 106.5143\n",
      "Epoch 153/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 139.8126 - val_loss: 106.0444\n",
      "Epoch 154/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 139.4502 - val_loss: 107.1948\n",
      "Epoch 155/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 138.5739 - val_loss: 103.3919\n",
      "Epoch 156/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 138.0943 - val_loss: 107.2041\n",
      "Epoch 157/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 137.5152 - val_loss: 101.6259\n",
      "Epoch 158/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 136.9087 - val_loss: 102.4469\n",
      "Epoch 159/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 135.7892 - val_loss: 102.4589\n",
      "Epoch 160/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 135.0235 - val_loss: 100.9737\n",
      "Epoch 161/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 134.1995 - val_loss: 99.2156\n",
      "Epoch 162/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 133.4583 - val_loss: 98.6574\n",
      "Epoch 163/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 132.4349 - val_loss: 99.6966\n",
      "Epoch 164/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 131.6870 - val_loss: 97.9139\n",
      "Epoch 165/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 131.0680 - val_loss: 93.7758\n",
      "Epoch 166/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 130.2560 - val_loss: 97.2725\n",
      "Epoch 167/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 128.8803 - val_loss: 94.4044\n",
      "Epoch 168/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 127.7270 - val_loss: 93.1775\n",
      "Epoch 169/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 126.4759 - val_loss: 91.2505\n",
      "Epoch 170/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 125.2365 - val_loss: 92.6006\n",
      "Epoch 171/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 124.2377 - val_loss: 87.9596\n",
      "Epoch 172/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 122.6085 - val_loss: 85.9866\n",
      "Epoch 173/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 120.3681 - val_loss: 85.1587\n",
      "Epoch 174/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 117.9486 - val_loss: 84.4175\n",
      "Epoch 175/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 115.0249 - val_loss: 76.9735\n",
      "Epoch 176/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 112.1192 - val_loss: 77.1872\n",
      "Epoch 177/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 108.9062 - val_loss: 79.5443\n",
      "Epoch 178/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 107.4944 - val_loss: 74.6774\n",
      "Epoch 179/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 105.2979 - val_loss: 64.9143\n",
      "Epoch 180/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 104.6579 - val_loss: 63.4773\n",
      "Epoch 181/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 103.5891 - val_loss: 67.9730\n",
      "Epoch 182/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 100.1516 - val_loss: 69.9386\n",
      "Epoch 183/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 98.5312 - val_loss: 67.9695\n",
      "Epoch 184/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 97.1533 - val_loss: 64.9093\n",
      "Epoch 185/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 95.9219 - val_loss: 62.0709\n",
      "Epoch 186/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 95.0462 - val_loss: 63.2266\n",
      "Epoch 187/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 93.8817 - val_loss: 66.5938\n",
      "Epoch 188/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 93.0316 - val_loss: 62.6324\n",
      "Epoch 189/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 91.8154 - val_loss: 61.4353\n",
      "Epoch 190/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 90.8574 - val_loss: 59.9941\n",
      "Epoch 191/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 89.8771 - val_loss: 58.5947\n",
      "Epoch 192/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 88.8579 - val_loss: 61.7069\n",
      "Epoch 193/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 88.1823 - val_loss: 57.4792\n",
      "Epoch 194/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 87.3085 - val_loss: 55.6717\n",
      "Epoch 195/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 86.8587 - val_loss: 54.6686\n",
      "Epoch 196/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 85.9810 - val_loss: 54.0122\n",
      "Epoch 197/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 86.0015 - val_loss: 54.7161\n",
      "Epoch 198/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 84.9890 - val_loss: 55.8725\n",
      "Epoch 199/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 84.4729 - val_loss: 56.7271\n",
      "Epoch 200/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 84.4384 - val_loss: 58.5211\n",
      "Epoch 201/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 84.2242 - val_loss: 60.3453\n",
      "Epoch 202/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 84.0843 - val_loss: 56.0650\n",
      "Epoch 203/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 85.3582 - val_loss: 56.2585\n",
      "Epoch 204/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 85.1625 - val_loss: 50.3503\n",
      "Epoch 205/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 84.0653 - val_loss: 49.8783\n",
      "Epoch 206/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 83.8607 - val_loss: 50.0453\n",
      "Epoch 207/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 83.4666 - val_loss: 57.6330\n",
      "Epoch 208/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 82.9628 - val_loss: 62.4411\n",
      "Epoch 209/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 83.6322 - val_loss: 58.1887\n",
      "Epoch 210/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 82.9126 - val_loss: 54.8985\n",
      "Epoch 211/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 82.6581 - val_loss: 50.8979\n",
      "Epoch 212/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 82.2756 - val_loss: 50.8298\n",
      "Epoch 213/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 82.5056 - val_loss: 53.3192\n",
      "Epoch 214/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.9875 - val_loss: 53.3839\n",
      "Epoch 215/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.8045 - val_loss: 56.3354\n",
      "Epoch 216/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.8838 - val_loss: 55.9897\n",
      "Epoch 217/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 82.0032 - val_loss: 55.7895\n",
      "Epoch 218/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.6719 - val_loss: 53.3922\n",
      "Epoch 219/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 81.6073 - val_loss: 55.3462\n",
      "Epoch 220/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 81.7861 - val_loss: 58.4394\n",
      "Epoch 221/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.8334 - val_loss: 55.4853\n",
      "Epoch 222/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.3563 - val_loss: 57.6339\n",
      "Epoch 223/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.6790 - val_loss: 54.8085\n",
      "Epoch 224/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.3056 - val_loss: 56.2504\n",
      "Epoch 225/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.0750 - val_loss: 53.6068\n",
      "Epoch 226/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.1131 - val_loss: 51.0887\n",
      "Epoch 227/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.2372 - val_loss: 54.1423\n",
      "Epoch 228/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 81.9272 - val_loss: 57.7829\n",
      "Epoch 229/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 81.2721 - val_loss: 60.7352\n",
      "Epoch 230/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 81.4656 - val_loss: 58.8353\n",
      "Epoch 231/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.3856 - val_loss: 51.0603\n",
      "Epoch 232/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 81.5274 - val_loss: 49.4232\n",
      "Epoch 233/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.4470 - val_loss: 47.9881\n",
      "Epoch 234/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 81.6550 - val_loss: 55.1156\n",
      "Epoch 235/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 80.7240 - val_loss: 57.5002\n",
      "Epoch 236/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 80.8748 - val_loss: 58.9554\n",
      "Epoch 237/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.4407 - val_loss: 60.3246\n",
      "Epoch 238/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.5257 - val_loss: 57.9446\n",
      "Epoch 239/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.0684 - val_loss: 51.8354\n",
      "Epoch 240/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.0971 - val_loss: 49.8320\n",
      "Epoch 241/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.5117 - val_loss: 50.2544\n",
      "Epoch 242/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.7126 - val_loss: 54.4429\n",
      "Epoch 243/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.3497 - val_loss: 56.4453\n",
      "Epoch 244/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.1772 - val_loss: 54.6914\n",
      "Epoch 245/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.1845 - val_loss: 52.5760\n",
      "Epoch 246/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.1720 - val_loss: 55.4438\n",
      "Epoch 247/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.4081 - val_loss: 57.2488\n",
      "Epoch 248/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.5960 - val_loss: 51.1283\n",
      "Epoch 249/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.5671 - val_loss: 49.1135\n",
      "Epoch 250/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.4410 - val_loss: 50.6615\n",
      "Epoch 251/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.8571 - val_loss: 53.6376\n",
      "Epoch 252/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.1538 - val_loss: 51.9044\n",
      "Epoch 253/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.8737 - val_loss: 54.5598\n",
      "Epoch 254/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.4697 - val_loss: 61.7916\n",
      "Epoch 255/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.2464 - val_loss: 52.7189\n",
      "Epoch 256/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.6638 - val_loss: 53.5072\n",
      "Epoch 257/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.7424 - val_loss: 53.1684\n",
      "Epoch 258/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.9538 - val_loss: 49.2378\n",
      "Epoch 259/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.9043 - val_loss: 53.7745\n",
      "Epoch 260/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 80.3696 - val_loss: 58.7084\n",
      "Epoch 261/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 80.1792 - val_loss: 57.4212\n",
      "Epoch 262/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.1249 - val_loss: 67.4156\n",
      "Epoch 263/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.0250 - val_loss: 52.0758\n",
      "Epoch 264/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.5052 - val_loss: 52.7002\n",
      "Epoch 265/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.7560 - val_loss: 50.3286\n",
      "Epoch 266/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.9581 - val_loss: 51.0527\n",
      "Epoch 267/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.6651 - val_loss: 48.7509\n",
      "Epoch 268/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.8058 - val_loss: 50.6056\n",
      "Epoch 269/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.2357 - val_loss: 55.3197\n",
      "Epoch 270/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 79.3761 - val_loss: 52.0562\n",
      "Epoch 271/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.7078 - val_loss: 59.3017\n",
      "Epoch 272/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.0128 - val_loss: 64.0913\n",
      "Epoch 273/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.9367 - val_loss: 49.7224\n",
      "Epoch 274/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.4594 - val_loss: 47.8648\n",
      "Epoch 275/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.8235 - val_loss: 49.3768\n",
      "Epoch 276/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.7428 - val_loss: 49.7757\n",
      "Epoch 277/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.0459 - val_loss: 56.6080\n",
      "Epoch 278/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.5795 - val_loss: 60.3830\n",
      "Epoch 279/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.6479 - val_loss: 53.9666\n",
      "Epoch 280/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.0569 - val_loss: 52.3115\n",
      "Epoch 281/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.9669 - val_loss: 50.0686\n",
      "Epoch 282/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.9643 - val_loss: 49.4532\n",
      "Epoch 283/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.1627 - val_loss: 52.0229\n",
      "Epoch 284/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.8606 - val_loss: 52.1970\n",
      "Epoch 285/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.9682 - val_loss: 52.3636\n",
      "Epoch 286/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.8612 - val_loss: 51.9705\n",
      "Epoch 287/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.8168 - val_loss: 54.6632\n",
      "Epoch 288/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.0375 - val_loss: 55.2022\n",
      "Epoch 289/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.0833 - val_loss: 54.1793\n",
      "Epoch 290/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.8277 - val_loss: 54.9987\n",
      "Epoch 291/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.1162 - val_loss: 58.6813\n",
      "Epoch 292/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.9305 - val_loss: 51.1341\n",
      "Epoch 293/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.5757 - val_loss: 53.3054\n",
      "Epoch 294/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.6022 - val_loss: 53.2320\n",
      "Epoch 295/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.5596 - val_loss: 52.9190\n",
      "Epoch 296/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.5184 - val_loss: 50.1617\n",
      "Epoch 297/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.6383 - val_loss: 48.6836\n",
      "Epoch 298/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.7835 - val_loss: 48.9532\n",
      "Epoch 299/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.7934 - val_loss: 49.7244\n",
      "Epoch 300/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.4850 - val_loss: 51.5736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.7181 - val_loss: 52.6787\n",
      "Epoch 302/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.7540 - val_loss: 57.1292\n",
      "Epoch 303/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.9642 - val_loss: 59.3592\n",
      "Epoch 304/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.8691 - val_loss: 61.1157\n",
      "Epoch 305/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.4882 - val_loss: 61.0357\n",
      "Epoch 306/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.0053 - val_loss: 51.8686\n",
      "Epoch 307/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.5575 - val_loss: 54.2397\n",
      "Epoch 308/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.9572 - val_loss: 55.3365\n",
      "Epoch 309/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.4609 - val_loss: 52.1010\n",
      "Epoch 310/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.3198 - val_loss: 51.9396\n",
      "Epoch 311/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.4478 - val_loss: 46.6643\n",
      "Epoch 312/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.3699 - val_loss: 48.1993\n",
      "Epoch 313/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.4549 - val_loss: 49.3607\n",
      "Epoch 314/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.0019 - val_loss: 51.0806\n",
      "Epoch 315/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.4933 - val_loss: 50.1227\n",
      "Epoch 316/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.7629 - val_loss: 57.2001\n",
      "Epoch 317/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.6986 - val_loss: 55.5866\n",
      "Epoch 318/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.2085 - val_loss: 50.9203\n",
      "Epoch 319/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.8807 - val_loss: 53.1063\n",
      "Epoch 320/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.7280 - val_loss: 51.6693\n",
      "Epoch 321/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.1683 - val_loss: 47.4895\n",
      "Epoch 322/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.9294 - val_loss: 47.8247\n",
      "Epoch 323/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.3294 - val_loss: 49.8903\n",
      "Epoch 324/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.1005 - val_loss: 51.1133\n",
      "Epoch 325/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.9260 - val_loss: 55.8885\n",
      "Epoch 326/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.3217 - val_loss: 50.3938\n",
      "Epoch 327/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.8790 - val_loss: 53.9545\n",
      "Epoch 328/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.5533 - val_loss: 57.6679\n",
      "Epoch 329/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.8486 - val_loss: 53.3970\n",
      "Epoch 330/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.3243 - val_loss: 51.2342\n",
      "Epoch 331/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.3175 - val_loss: 51.3984\n",
      "Epoch 332/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.1659 - val_loss: 58.8226\n",
      "Epoch 333/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.3143 - val_loss: 55.6483\n",
      "Epoch 334/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.8631 - val_loss: 55.8590\n",
      "Epoch 335/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.9265 - val_loss: 63.1147\n",
      "Epoch 336/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 81.2808 - val_loss: 60.1848\n",
      "Epoch 337/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.5450 - val_loss: 53.4592\n",
      "Epoch 338/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.3411 - val_loss: 47.6525\n",
      "Epoch 339/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 79.3972 - val_loss: 46.3927\n",
      "Epoch 340/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.7301 - val_loss: 46.3762\n",
      "Epoch 341/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 80.3033 - val_loss: 47.5599\n",
      "Epoch 342/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.7397 - val_loss: 50.3055\n",
      "Epoch 343/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.7835 - val_loss: 51.9538\n",
      "Epoch 344/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.0109 - val_loss: 50.0938\n",
      "Epoch 345/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.8643 - val_loss: 50.6989\n",
      "Epoch 346/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.3498 - val_loss: 48.9135\n",
      "Epoch 347/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.1308 - val_loss: 48.8009\n",
      "Epoch 348/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.7522 - val_loss: 48.5449\n",
      "Epoch 349/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.7581 - val_loss: 49.8554\n",
      "Epoch 350/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.6110 - val_loss: 53.4746\n",
      "Epoch 351/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.6746 - val_loss: 55.8509\n",
      "Epoch 352/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.1209 - val_loss: 56.0488\n",
      "Epoch 353/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.9455 - val_loss: 58.9193\n",
      "Epoch 354/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.3835 - val_loss: 57.6005\n",
      "Epoch 355/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.9137 - val_loss: 50.1855\n",
      "Epoch 356/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.8652 - val_loss: 51.3996\n",
      "Epoch 357/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.6535 - val_loss: 48.4166\n",
      "Epoch 358/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.9260 - val_loss: 47.1980\n",
      "Epoch 359/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.7367 - val_loss: 52.6996\n",
      "Epoch 360/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.5742 - val_loss: 50.8319\n",
      "Epoch 361/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.6041 - val_loss: 50.0759\n",
      "Epoch 362/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.4206 - val_loss: 48.1334\n",
      "Epoch 363/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.7352 - val_loss: 50.7630\n",
      "Epoch 364/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.6418 - val_loss: 48.6101\n",
      "Epoch 365/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.7879 - val_loss: 50.2536\n",
      "Epoch 366/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.7263 - val_loss: 52.3533\n",
      "Epoch 367/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.6320 - val_loss: 51.1414\n",
      "Epoch 368/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.4371 - val_loss: 52.2050\n",
      "Epoch 369/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.3388 - val_loss: 52.4858\n",
      "Epoch 370/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.6294 - val_loss: 52.8551\n",
      "Epoch 371/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.1208 - val_loss: 50.5499\n",
      "Epoch 372/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.4895 - val_loss: 51.2294\n",
      "Epoch 373/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 78.1548 - val_loss: 51.5323\n",
      "Epoch 374/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.4512 - val_loss: 50.0794\n",
      "Epoch 375/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.2458 - val_loss: 48.7949\n",
      "Epoch 376/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.6739 - val_loss: 51.1807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.5187 - val_loss: 53.6481\n",
      "Epoch 378/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.9714 - val_loss: 50.4530\n",
      "Epoch 379/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.7924 - val_loss: 51.4608\n",
      "Epoch 380/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.4366 - val_loss: 51.9300\n",
      "Epoch 381/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.3015 - val_loss: 47.3549\n",
      "Epoch 382/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.6921 - val_loss: 52.1044\n",
      "Epoch 383/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.6277 - val_loss: 53.5123\n",
      "Epoch 384/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.3260 - val_loss: 50.7087\n",
      "Epoch 385/500\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 77.1884 - val_loss: 52.3662\n",
      "Epoch 386/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.3330 - val_loss: 54.8096\n",
      "Epoch 387/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.4691 - val_loss: 53.6595\n",
      "Epoch 388/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.3382 - val_loss: 51.8445\n",
      "Epoch 389/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.9668 - val_loss: 52.0855\n",
      "Epoch 390/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.5363 - val_loss: 50.0461\n",
      "Epoch 391/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.8633 - val_loss: 52.3337\n",
      "Epoch 392/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.8844 - val_loss: 50.3476\n",
      "Epoch 393/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.7889 - val_loss: 51.3874\n",
      "Epoch 394/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.7083 - val_loss: 50.7364\n",
      "Epoch 395/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.1936 - val_loss: 46.3500\n",
      "Epoch 396/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.4594 - val_loss: 48.0808\n",
      "Epoch 397/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.1932 - val_loss: 51.0761\n",
      "Epoch 398/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.3785 - val_loss: 48.4696\n",
      "Epoch 399/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.4318 - val_loss: 51.1896\n",
      "Epoch 400/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.1553 - val_loss: 51.3347\n",
      "Epoch 401/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.2171 - val_loss: 59.4335\n",
      "Epoch 402/500\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 77.3795 - val_loss: 55.3667\n",
      "Epoch 403/500\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 77.3178 - val_loss: 52.9328\n",
      "Epoch 404/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.3615 - val_loss: 55.5965\n",
      "Epoch 405/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.0104 - val_loss: 50.8671\n",
      "Epoch 406/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.3071 - val_loss: 48.7459\n",
      "Epoch 407/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.6481 - val_loss: 47.8684\n",
      "Epoch 408/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.0726 - val_loss: 49.9232\n",
      "Epoch 409/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.9741 - val_loss: 50.1558\n",
      "Epoch 410/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.0947 - val_loss: 47.7409\n",
      "Epoch 411/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.1939 - val_loss: 49.7845\n",
      "Epoch 412/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.8876 - val_loss: 48.8251\n",
      "Epoch 413/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.7883 - val_loss: 51.9613\n",
      "Epoch 414/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.5739 - val_loss: 49.0280\n",
      "Epoch 415/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.9454 - val_loss: 47.9054\n",
      "Epoch 416/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.4023 - val_loss: 48.1550\n",
      "Epoch 417/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.8320 - val_loss: 52.8318\n",
      "Epoch 418/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.2525 - val_loss: 54.4510\n",
      "Epoch 419/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.2506 - val_loss: 54.4773\n",
      "Epoch 420/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.3650 - val_loss: 53.6633\n",
      "Epoch 421/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.3579 - val_loss: 47.4730\n",
      "Epoch 422/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.1263 - val_loss: 51.2315\n",
      "Epoch 423/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.9439 - val_loss: 51.4297\n",
      "Epoch 424/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.7165 - val_loss: 48.8784\n",
      "Epoch 425/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.0632 - val_loss: 52.5743\n",
      "Epoch 426/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.0275 - val_loss: 55.4362\n",
      "Epoch 427/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.1674 - val_loss: 57.1347\n",
      "Epoch 428/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.6837 - val_loss: 52.4859\n",
      "Epoch 429/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.0990 - val_loss: 48.1592\n",
      "Epoch 430/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.2189 - val_loss: 47.7922\n",
      "Epoch 431/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.4010 - val_loss: 45.8406\n",
      "Epoch 432/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 78.6511 - val_loss: 45.6645\n",
      "Epoch 433/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.4556 - val_loss: 49.7138\n",
      "Epoch 434/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.6679 - val_loss: 47.9978\n",
      "Epoch 435/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.9527 - val_loss: 49.7579\n",
      "Epoch 436/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.6587 - val_loss: 52.3460\n",
      "Epoch 437/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.9034 - val_loss: 49.1266\n",
      "Epoch 438/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.6486 - val_loss: 54.2521\n",
      "Epoch 439/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.1241 - val_loss: 56.0981\n",
      "Epoch 440/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.3142 - val_loss: 52.1392\n",
      "Epoch 441/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.8625 - val_loss: 50.5113\n",
      "Epoch 442/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.8884 - val_loss: 50.7217\n",
      "Epoch 443/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.9593 - val_loss: 51.4429\n",
      "Epoch 444/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.0448 - val_loss: 48.4413\n",
      "Epoch 445/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.4979 - val_loss: 45.6112\n",
      "Epoch 446/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.8450 - val_loss: 47.6338\n",
      "Epoch 447/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.3969 - val_loss: 53.5954\n",
      "Epoch 448/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.3145 - val_loss: 52.0063\n",
      "Epoch 449/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.1482 - val_loss: 49.0634\n",
      "Epoch 450/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 78.3591 - val_loss: 47.7938\n",
      "Epoch 451/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.8790 - val_loss: 52.0026\n",
      "Epoch 452/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.7072 - val_loss: 50.2169\n",
      "Epoch 453/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.6251 - val_loss: 53.9841\n",
      "Epoch 454/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.9345 - val_loss: 54.7732\n",
      "Epoch 455/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.9898 - val_loss: 57.9814\n",
      "Epoch 456/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.6846 - val_loss: 52.8662\n",
      "Epoch 457/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.9377 - val_loss: 55.0368\n",
      "Epoch 458/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.1917 - val_loss: 54.2735\n",
      "Epoch 459/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.1816 - val_loss: 53.1715\n",
      "Epoch 460/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.5432 - val_loss: 51.3700\n",
      "Epoch 461/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.9034 - val_loss: 50.8554\n",
      "Epoch 462/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.5005 - val_loss: 48.7985\n",
      "Epoch 463/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 78.2187 - val_loss: 47.4838\n",
      "Epoch 464/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.7048 - val_loss: 50.9165\n",
      "Epoch 465/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.1804 - val_loss: 47.6528\n",
      "Epoch 466/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.5784 - val_loss: 49.8522\n",
      "Epoch 467/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.5703 - val_loss: 49.1043\n",
      "Epoch 468/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.5357 - val_loss: 52.8512\n",
      "Epoch 469/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.6738 - val_loss: 52.8846\n",
      "Epoch 470/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.9296 - val_loss: 58.2177\n",
      "Epoch 471/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.1859 - val_loss: 59.4739\n",
      "Epoch 472/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.9358 - val_loss: 57.2038\n",
      "Epoch 473/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.7797 - val_loss: 56.2555\n",
      "Epoch 474/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.2648 - val_loss: 56.7864\n",
      "Epoch 475/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.9625 - val_loss: 57.9360\n",
      "Epoch 476/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.9964 - val_loss: 58.2073\n",
      "Epoch 477/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.8539 - val_loss: 52.7944\n",
      "Epoch 478/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.4112 - val_loss: 52.4529\n",
      "Epoch 479/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.1422 - val_loss: 50.6240\n",
      "Epoch 480/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.5774 - val_loss: 53.3105\n",
      "Epoch 481/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.4007 - val_loss: 55.1045\n",
      "Epoch 482/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.6092 - val_loss: 54.7724\n",
      "Epoch 483/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.7108 - val_loss: 50.4316\n",
      "Epoch 484/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.0303 - val_loss: 50.2326\n",
      "Epoch 485/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.4655 - val_loss: 52.9072\n",
      "Epoch 486/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.6397 - val_loss: 58.5717\n",
      "Epoch 487/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.4661 - val_loss: 62.7755\n",
      "Epoch 488/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 78.5687 - val_loss: 67.2231\n",
      "Epoch 489/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 78.1795 - val_loss: 60.7314\n",
      "Epoch 490/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.0142 - val_loss: 55.9516\n",
      "Epoch 491/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.5820 - val_loss: 51.9461\n",
      "Epoch 492/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.3206 - val_loss: 48.5617\n",
      "Epoch 493/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.4390 - val_loss: 46.7331\n",
      "Epoch 494/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.5487 - val_loss: 46.7050\n",
      "Epoch 495/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.6034 - val_loss: 49.7669\n",
      "Epoch 496/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.2472 - val_loss: 57.2786\n",
      "Epoch 497/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.3823 - val_loss: 56.8834\n",
      "Epoch 498/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.2872 - val_loss: 63.7361\n",
      "Epoch 499/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 77.5677 - val_loss: 56.3216\n",
      "Epoch 500/500\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 76.4497 - val_loss: 54.8336\n"
     ]
    }
   ],
   "source": [
    "modelConvLSTM = Sequential()\n",
    "modelConvLSTM.add(ConvLSTM2D(filters=32, kernel_size=(1,2), activation='relu', return_sequences=True,input_shape=(X_train.shape[1], 1, X_train.shape[3], X_train.shape[4])))\n",
    "modelConvLSTM.add(ConvLSTM2D(filters=16, kernel_size=(1,2), activation='relu'))\n",
    "modelConvLSTM.add(Flatten())\n",
    "modelConvLSTM.add(Dense(1))\n",
    "modelConvLSTM.compile(optimizer='adam', loss='mse')\n",
    "history = modelConvLSTM.fit(X_train, y_train, batch_size=512, epochs=500, verbose=1, callbacks=[early_stop], validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Explained Variance Score': 0.6574914445346058,\n",
       " 'Max Error': 39.8500033569336,\n",
       " 'Mean Absolute Error': 6.030188689151053,\n",
       " 'Mean Squared Error': 54.8335854195177,\n",
       " 'Root Mean Squared Error': 7.404970318611527,\n",
       " 'Median Absolute Error': 5.491190490722651,\n",
       " 'R² Score': 0.5836907923261785,\n",
       " 'Mean Absolute Percentage Error': 5.900770355168048}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvLSTMpred = modelConvLSTM.predict(X_valid, verbose=0)\n",
    "ConvLSTMpred = ConvLSTMpred.reshape((ConvLSTMpred.shape[0]))\n",
    "ConvLSTMresults = metrics(ConvLSTMpred, y_valid)\n",
    "ConvLSTMresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvLSTMpred = modelConvLSTM.predict(X_test, verbose=0)\n",
    "ConvLSTMpred = ConvLSTMpred.reshape((ConvLSTMpred.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
