{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten, TimeDistributed, ConvLSTM2D, Reshape\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics as sm\n",
    "import keras\n",
    "from keras.losses import huber_loss\n",
    "\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...  X375  X376  X377  X378  X379  \\\n",
       "0   0  130.81   k  v  at  a  d  u  j  o  ...     0     0     1     0     0   \n",
       "1   6   88.53   k  t  av  e  d  y  l  o  ...     1     0     0     0     0   \n",
       "2   7   76.26  az  w   n  c  d  x  j  x  ...     0     0     0     0     0   \n",
       "3   9   80.62  az  t   n  f  d  x  l  e  ...     0     0     0     0     0   \n",
       "4  13   78.02  az  v   n  f  d  h  d  n  ...     0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  data.drop([\"ID\",\"X0\",\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X8\" ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        y  X10  X11  X12  X13  X14  X15  X16  X17  X18  ...  X375  X376  X377  \\\n",
       "0  130.81    0    0    0    1    0    0    0    0    1  ...     0     0     1   \n",
       "1   88.53    0    0    0    0    0    0    0    0    1  ...     1     0     0   \n",
       "2   76.26    0    0    0    0    0    0    0    1    0  ...     0     0     0   \n",
       "3   80.62    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "4   78.02    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "\n",
       "   X378  X379  X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0  \n",
       "2     0     0     0     1     0     0     0  \n",
       "3     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 369 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 369)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>b</td>\n",
       "      <td>ai</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>as</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>j</td>\n",
       "      <td>j</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>az</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>z</td>\n",
       "      <td>l</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>w</td>\n",
       "      <td>s</td>\n",
       "      <td>as</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>i</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>8410</td>\n",
       "      <td>aj</td>\n",
       "      <td>h</td>\n",
       "      <td>as</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>aa</td>\n",
       "      <td>j</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>8411</td>\n",
       "      <td>t</td>\n",
       "      <td>aa</td>\n",
       "      <td>ai</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>aa</td>\n",
       "      <td>j</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>8413</td>\n",
       "      <td>y</td>\n",
       "      <td>v</td>\n",
       "      <td>as</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>aa</td>\n",
       "      <td>d</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>8414</td>\n",
       "      <td>ak</td>\n",
       "      <td>v</td>\n",
       "      <td>as</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>aa</td>\n",
       "      <td>c</td>\n",
       "      <td>q</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>8416</td>\n",
       "      <td>t</td>\n",
       "      <td>aa</td>\n",
       "      <td>ai</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>aa</td>\n",
       "      <td>g</td>\n",
       "      <td>r</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4209 rows × 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  X0  X1  X2 X3 X4  X5 X6 X8  X10  ...  X375  X376  X377  X378  \\\n",
       "0        1  az   v   n  f  d   t  a  w    0  ...     0     0     0     1   \n",
       "1        2   t   b  ai  a  d   b  g  y    0  ...     0     0     1     0   \n",
       "2        3  az   v  as  f  d   a  j  j    0  ...     0     0     0     1   \n",
       "3        4  az   l   n  f  d   z  l  n    0  ...     0     0     0     1   \n",
       "4        5   w   s  as  c  d   y  i  m    0  ...     1     0     0     0   \n",
       "...    ...  ..  ..  .. .. ..  .. .. ..  ...  ...   ...   ...   ...   ...   \n",
       "4204  8410  aj   h  as  f  d  aa  j  e    0  ...     0     0     0     0   \n",
       "4205  8411   t  aa  ai  d  d  aa  j  y    0  ...     0     1     0     0   \n",
       "4206  8413   y   v  as  f  d  aa  d  w    0  ...     0     0     0     0   \n",
       "4207  8414  ak   v  as  a  d  aa  c  q    0  ...     0     0     1     0   \n",
       "4208  8416   t  aa  ai  c  d  aa  g  r    0  ...     1     0     0     0   \n",
       "\n",
       "      X379  X380  X382  X383  X384  X385  \n",
       "0        0     0     0     0     0     0  \n",
       "1        0     0     0     0     0     0  \n",
       "2        0     0     0     0     0     0  \n",
       "3        0     0     0     0     0     0  \n",
       "4        0     0     0     0     0     0  \n",
       "...    ...   ...   ...   ...   ...   ...  \n",
       "4204     0     0     0     0     0     0  \n",
       "4205     0     0     0     0     0     0  \n",
       "4206     0     0     0     0     0     0  \n",
       "4207     0     0     0     0     0     0  \n",
       "4208     0     0     0     0     0     0  \n",
       "\n",
       "[4209 rows x 377 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest =  dtest.drop([\"ID\",\"X0\",\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X8\" ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 368 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X10  X11  X12  X13  X14  X15  X16  X17  X18  X19  ...  X375  X376  X377  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "1    0    0    0    0    0    0    0    0    0    1  ...     0     0     1   \n",
       "2    0    0    0    0    1    0    0    0    0    0  ...     0     0     0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
       "4    0    0    0    0    1    0    0    0    0    0  ...     1     0     0   \n",
       "\n",
       "   X378  X379  X380  X382  X383  X384  X385  \n",
       "0     1     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0  \n",
       "2     1     0     0     0     0     0     0  \n",
       "3     1     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 368 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 368)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data.values[0:3499,1:], data.values[0:3499, :1].ravel()\n",
    "X_valid, y_valid = data.values[3500:4208,1:], data.values[3500:4208, :1].ravel()\n",
    "X_test = dtest.values[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train---- (3499, 368)\n",
      "y_train---- (3499,)\n",
      "X_valid---- (708, 368)\n",
      "y_valid---- (708,)\n",
      "X_test----- (4209, 368)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train----\",X_train.shape)\n",
    "print(\"y_train----\",y_train.shape)      \n",
    "print(\"X_valid----\",X_valid.shape)\n",
    "print(\"y_valid----\",y_valid.shape)\n",
    "print(\"X_test-----\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130.81"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = min_max_scaler.fit_transform(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(pred, y_test):\n",
    "    evs = sm.explained_variance_score(y_test, pred)\n",
    "    me = sm.max_error(y_test, pred)\n",
    "    mae = sm.mean_absolute_error(y_test, pred)\n",
    "    mse = sm.mean_squared_error(y_test, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    #msle = sm.mean_squared_log_error(y_test, pred)\n",
    "    m_ae = sm.median_absolute_error(y_test, pred)\n",
    "    r2 = sm.r2_score(y_test, pred)\n",
    "    #mpd = sm.mean_poisson_deviance(y_test, pred)\n",
    "    #mgd = sm.mean_gamma_deviance(y_test, pred)\n",
    "    mape = mean_absolute_percentage_error(pred, y_test)\n",
    "    return({'Explained Variance Score': evs,\n",
    "            'Max Error': me,\n",
    "            'Mean Absolute Error': mae,\n",
    "            'Mean Squared Error': mse,\n",
    "            'Root Mean Squared Error': rmse,\n",
    "            #'Mean Squared Log Error': msle,\n",
    "            'Median Absolute Error': m_ae,\n",
    "            'R² Score': r2,\n",
    "            #'Mean Poisson Deviance': mpd,\n",
    "            #'Mean Gamma Deviance': mgd,\n",
    "            'Mean Absolute Percentage Error': mape\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsequences = 2\n",
    "timesteps = X_train.shape[1]//subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], subsequences, 1, timesteps, 1))\n",
    "X_valid = X_valid.reshape((X_valid.shape[0], subsequences, 1, timesteps, 1))\n",
    "X_test  = X_test.reshape((X_test.shape[0], subsequences, 1, timesteps, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3499, 2, 1, 184, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3499 samples, validate on 708 samples\n",
      "Epoch 1/700\n",
      " - 67s - loss: 99.9378 - val_loss: 96.3830\n",
      "Epoch 2/700\n",
      " - 47s - loss: 94.6588 - val_loss: 84.5971\n",
      "Epoch 3/700\n",
      " - 47s - loss: 73.0430 - val_loss: 43.4973\n",
      "Epoch 4/700\n",
      " - 47s - loss: 25.2121 - val_loss: 28.4330\n",
      "Epoch 5/700\n",
      " - 47s - loss: 16.4671 - val_loss: 14.5747\n",
      "Epoch 6/700\n",
      " - 48s - loss: 13.6031 - val_loss: 10.1783\n",
      "Epoch 7/700\n",
      " - 46s - loss: 11.2562 - val_loss: 8.8845\n",
      "Epoch 8/700\n",
      " - 46s - loss: 10.3438 - val_loss: 8.9709\n",
      "Epoch 9/700\n",
      " - 46s - loss: 9.7981 - val_loss: 9.6385\n",
      "Epoch 10/700\n",
      " - 47s - loss: 9.7467 - val_loss: 8.9028\n",
      "Epoch 11/700\n",
      " - 47s - loss: 9.5906 - val_loss: 9.0960\n",
      "Epoch 12/700\n",
      " - 46s - loss: 9.5703 - val_loss: 8.7840\n",
      "Epoch 13/700\n",
      " - 46s - loss: 9.4975 - val_loss: 8.8632\n",
      "Epoch 14/700\n",
      " - 46s - loss: 9.4670 - val_loss: 8.7544\n",
      "Epoch 15/700\n",
      " - 46s - loss: 9.4209 - val_loss: 8.7532\n",
      "Epoch 16/700\n",
      " - 47s - loss: 9.3968 - val_loss: 8.7103\n",
      "Epoch 17/700\n",
      " - 46s - loss: 9.3694 - val_loss: 8.6838\n",
      "Epoch 18/700\n",
      " - 47s - loss: 9.3472 - val_loss: 8.6503\n",
      "Epoch 19/700\n",
      " - 46s - loss: 9.3294 - val_loss: 8.6717\n",
      "Epoch 20/700\n",
      " - 46s - loss: 9.2904 - val_loss: 8.5604\n",
      "Epoch 21/700\n",
      " - 46s - loss: 9.2456 - val_loss: 8.5664\n",
      "Epoch 22/700\n",
      " - 47s - loss: 9.2186 - val_loss: 8.5498\n",
      "Epoch 23/700\n",
      " - 46s - loss: 9.1661 - val_loss: 8.4698\n",
      "Epoch 24/700\n",
      " - 46s - loss: 9.1257 - val_loss: 8.4238\n",
      "Epoch 25/700\n",
      " - 46s - loss: 9.0841 - val_loss: 8.3785\n",
      "Epoch 26/700\n",
      " - 46s - loss: 9.0297 - val_loss: 8.3420\n",
      "Epoch 27/700\n",
      " - 46s - loss: 8.9793 - val_loss: 8.3205\n",
      "Epoch 28/700\n",
      " - 46s - loss: 8.9412 - val_loss: 8.2515\n",
      "Epoch 29/700\n",
      " - 46s - loss: 8.8687 - val_loss: 8.1671\n",
      "Epoch 30/700\n",
      " - 46s - loss: 8.8104 - val_loss: 8.0839\n",
      "Epoch 31/700\n",
      " - 46s - loss: 8.7422 - val_loss: 8.1143\n",
      "Epoch 32/700\n",
      " - 46s - loss: 8.6858 - val_loss: 7.9219\n",
      "Epoch 33/700\n",
      " - 47s - loss: 8.6129 - val_loss: 8.0261\n",
      "Epoch 34/700\n",
      " - 48s - loss: 8.5358 - val_loss: 7.8290\n",
      "Epoch 35/700\n",
      " - 46s - loss: 8.4221 - val_loss: 7.6586\n",
      "Epoch 36/700\n",
      " - 46s - loss: 8.3265 - val_loss: 7.8229\n",
      "Epoch 37/700\n",
      " - 46s - loss: 8.2585 - val_loss: 7.4827\n",
      "Epoch 38/700\n",
      " - 46s - loss: 8.1167 - val_loss: 7.3572\n",
      "Epoch 39/700\n",
      " - 46s - loss: 8.0222 - val_loss: 7.2997\n",
      "Epoch 40/700\n",
      " - 46s - loss: 7.9175 - val_loss: 7.1922\n",
      "Epoch 41/700\n",
      " - 46s - loss: 7.7989 - val_loss: 7.4943\n",
      "Epoch 42/700\n",
      " - 46s - loss: 7.7385 - val_loss: 7.1941\n",
      "Epoch 43/700\n",
      " - 46s - loss: 7.6070 - val_loss: 6.9826\n",
      "Epoch 44/700\n",
      " - 46s - loss: 7.5626 - val_loss: 6.8959\n",
      "Epoch 45/700\n",
      " - 46s - loss: 7.4531 - val_loss: 7.3213\n",
      "Epoch 46/700\n",
      " - 46s - loss: 7.4275 - val_loss: 6.7693\n",
      "Epoch 47/700\n",
      " - 48s - loss: 7.1435 - val_loss: 6.5973\n",
      "Epoch 48/700\n",
      " - 47s - loss: 7.0111 - val_loss: 6.1691\n",
      "Epoch 49/700\n",
      " - 47s - loss: 6.8717 - val_loss: 6.1052\n",
      "Epoch 50/700\n",
      " - 46s - loss: 6.7457 - val_loss: 5.8587\n",
      "Epoch 51/700\n",
      " - 46s - loss: 6.6421 - val_loss: 5.8542\n",
      "Epoch 52/700\n",
      " - 46s - loss: 6.5538 - val_loss: 5.9811\n",
      "Epoch 53/700\n",
      " - 47s - loss: 6.4850 - val_loss: 5.9917\n",
      "Epoch 54/700\n",
      " - 46s - loss: 6.4031 - val_loss: 5.5970\n",
      "Epoch 55/700\n",
      " - 47s - loss: 6.2949 - val_loss: 5.2319\n",
      "Epoch 56/700\n",
      " - 47s - loss: 6.1711 - val_loss: 5.1373\n",
      "Epoch 57/700\n",
      " - 46s - loss: 6.0608 - val_loss: 5.0259\n",
      "Epoch 58/700\n",
      " - 46s - loss: 6.0888 - val_loss: 5.3464\n",
      "Epoch 59/700\n",
      " - 46s - loss: 5.9708 - val_loss: 5.4845\n",
      "Epoch 60/700\n",
      " - 46s - loss: 5.8572 - val_loss: 5.4625\n",
      "Epoch 61/700\n",
      " - 46s - loss: 5.7759 - val_loss: 5.0612\n",
      "Epoch 62/700\n",
      " - 46s - loss: 5.6808 - val_loss: 4.8805\n",
      "Epoch 63/700\n",
      " - 46s - loss: 5.6478 - val_loss: 5.2643\n",
      "Epoch 64/700\n",
      " - 46s - loss: 5.5659 - val_loss: 4.7248\n",
      "Epoch 65/700\n",
      " - 46s - loss: 5.5220 - val_loss: 4.8735\n",
      "Epoch 66/700\n",
      " - 46s - loss: 5.4617 - val_loss: 4.9372\n",
      "Epoch 67/700\n",
      " - 46s - loss: 5.4483 - val_loss: 4.8385\n",
      "Epoch 68/700\n",
      " - 47s - loss: 5.3930 - val_loss: 4.9383\n",
      "Epoch 69/700\n",
      " - 47s - loss: 5.4330 - val_loss: 4.5242\n",
      "Epoch 70/700\n",
      " - 46s - loss: 5.3822 - val_loss: 5.0176\n",
      "Epoch 71/700\n",
      " - 46s - loss: 5.3237 - val_loss: 4.5603\n",
      "Epoch 72/700\n",
      " - 47s - loss: 5.2857 - val_loss: 5.3952\n",
      "Epoch 73/700\n",
      " - 46s - loss: 5.3516 - val_loss: 4.5483\n",
      "Epoch 74/700\n",
      " - 46s - loss: 5.2532 - val_loss: 4.5321\n",
      "Epoch 75/700\n",
      " - 47s - loss: 5.2727 - val_loss: 4.8046\n",
      "Epoch 76/700\n",
      " - 46s - loss: 5.2254 - val_loss: 4.3198\n",
      "Epoch 77/700\n",
      " - 46s - loss: 5.3147 - val_loss: 5.1895\n",
      "Epoch 78/700\n",
      " - 46s - loss: 5.2611 - val_loss: 4.5111\n",
      "Epoch 79/700\n",
      " - 46s - loss: 5.1968 - val_loss: 4.6247\n",
      "Epoch 80/700\n",
      " - 46s - loss: 5.2363 - val_loss: 4.7906\n",
      "Epoch 81/700\n",
      " - 46s - loss: 5.2291 - val_loss: 4.4391\n",
      "Epoch 82/700\n",
      " - 46s - loss: 5.1580 - val_loss: 4.4188\n",
      "Epoch 83/700\n",
      " - 46s - loss: 5.1640 - val_loss: 4.6695\n",
      "Epoch 84/700\n",
      " - 46s - loss: 5.2072 - val_loss: 4.6312\n",
      "Epoch 85/700\n",
      " - 46s - loss: 5.1366 - val_loss: 4.6995\n",
      "Epoch 86/700\n",
      " - 46s - loss: 5.1435 - val_loss: 4.3766\n",
      "Epoch 87/700\n",
      " - 46s - loss: 5.1219 - val_loss: 4.4225\n",
      "Epoch 88/700\n",
      " - 46s - loss: 5.2553 - val_loss: 5.5460\n",
      "Epoch 89/700\n",
      " - 46s - loss: 5.2821 - val_loss: 4.2475\n",
      "Epoch 90/700\n",
      " - 46s - loss: 5.2522 - val_loss: 5.3847\n",
      "Epoch 91/700\n",
      " - 47s - loss: 5.1730 - val_loss: 4.3455\n",
      "Epoch 92/700\n",
      " - 47s - loss: 5.1540 - val_loss: 4.8757\n",
      "Epoch 93/700\n",
      " - 46s - loss: 5.1592 - val_loss: 4.2158\n",
      "Epoch 94/700\n",
      " - 46s - loss: 5.1464 - val_loss: 4.9741\n",
      "Epoch 95/700\n",
      " - 46s - loss: 5.1552 - val_loss: 4.7129\n",
      "Epoch 96/700\n",
      " - 46s - loss: 5.1122 - val_loss: 4.3333\n",
      "Epoch 97/700\n",
      " - 46s - loss: 5.1132 - val_loss: 5.6337\n",
      "Epoch 98/700\n",
      " - 46s - loss: 5.2833 - val_loss: 4.1571\n",
      "Epoch 99/700\n",
      " - 46s - loss: 5.2447 - val_loss: 5.1002\n",
      "Epoch 100/700\n",
      " - 46s - loss: 5.1111 - val_loss: 4.5597\n",
      "Epoch 101/700\n",
      " - 46s - loss: 5.0957 - val_loss: 4.8384\n",
      "Epoch 102/700\n",
      " - 46s - loss: 5.1148 - val_loss: 4.2315\n",
      "Epoch 103/700\n",
      " - 46s - loss: 5.0925 - val_loss: 4.8821\n",
      "Epoch 104/700\n",
      " - 47s - loss: 5.0315 - val_loss: 4.6344\n",
      "Epoch 105/700\n",
      " - 46s - loss: 5.0313 - val_loss: 4.3787\n",
      "Epoch 106/700\n",
      " - 47s - loss: 5.0296 - val_loss: 4.6314\n",
      "Epoch 107/700\n",
      " - 47s - loss: 5.0505 - val_loss: 4.6049\n",
      "Epoch 108/700\n",
      " - 47s - loss: 5.0318 - val_loss: 4.6523\n",
      "Epoch 109/700\n",
      " - 46s - loss: 5.0424 - val_loss: 4.3318\n",
      "Epoch 110/700\n",
      " - 46s - loss: 5.0631 - val_loss: 4.8345\n",
      "Epoch 111/700\n",
      " - 46s - loss: 5.0646 - val_loss: 4.2014\n",
      "Epoch 112/700\n",
      " - 46s - loss: 5.0585 - val_loss: 5.0236\n",
      "Epoch 113/700\n",
      " - 47s - loss: 5.0566 - val_loss: 4.3083\n",
      "Epoch 114/700\n",
      " - 46s - loss: 5.0020 - val_loss: 4.7754\n",
      "Epoch 115/700\n",
      " - 46s - loss: 5.0008 - val_loss: 4.2774\n",
      "Epoch 116/700\n",
      " - 46s - loss: 5.0857 - val_loss: 5.0290\n",
      "Epoch 117/700\n",
      " - 47s - loss: 5.0926 - val_loss: 4.4060\n",
      "Epoch 118/700\n",
      " - 46s - loss: 5.0366 - val_loss: 4.2278\n",
      "Epoch 119/700\n",
      " - 46s - loss: 5.0702 - val_loss: 4.9638\n",
      "Epoch 120/700\n",
      " - 47s - loss: 4.9901 - val_loss: 4.3719\n",
      "Epoch 121/700\n",
      " - 47s - loss: 4.9976 - val_loss: 4.7575\n",
      "Epoch 122/700\n",
      " - 46s - loss: 5.0541 - val_loss: 4.3378\n",
      "Epoch 123/700\n",
      " - 47s - loss: 4.9790 - val_loss: 4.6831\n",
      "Epoch 124/700\n",
      " - 47s - loss: 4.9911 - val_loss: 4.2841\n",
      "Epoch 125/700\n",
      " - 46s - loss: 5.0013 - val_loss: 4.5826\n",
      "Epoch 126/700\n",
      " - 46s - loss: 4.9402 - val_loss: 4.4733\n",
      "Epoch 127/700\n",
      " - 46s - loss: 4.9427 - val_loss: 4.3155\n",
      "Epoch 128/700\n",
      " - 46s - loss: 4.9631 - val_loss: 4.6496\n",
      "Epoch 129/700\n",
      " - 47s - loss: 4.9362 - val_loss: 4.6955\n",
      "Epoch 130/700\n",
      " - 46s - loss: 4.9234 - val_loss: 4.3412\n",
      "Epoch 131/700\n",
      " - 46s - loss: 4.9232 - val_loss: 4.4860\n",
      "Epoch 132/700\n",
      " - 46s - loss: 4.9198 - val_loss: 4.3141\n",
      "Epoch 133/700\n",
      " - 46s - loss: 4.9438 - val_loss: 4.6173\n",
      "Epoch 134/700\n",
      " - 46s - loss: 4.9545 - val_loss: 4.2404\n",
      "Epoch 135/700\n",
      " - 46s - loss: 4.9693 - val_loss: 5.0015\n",
      "Epoch 136/700\n",
      " - 47s - loss: 5.0631 - val_loss: 4.1012\n",
      "Epoch 137/700\n",
      " - 47s - loss: 5.0168 - val_loss: 4.9207\n",
      "Epoch 138/700\n",
      " - 46s - loss: 4.9469 - val_loss: 4.2382\n",
      "Epoch 139/700\n",
      " - 46s - loss: 4.8987 - val_loss: 4.4409\n",
      "Epoch 140/700\n",
      " - 46s - loss: 4.9053 - val_loss: 4.7144\n",
      "Epoch 141/700\n",
      " - 47s - loss: 4.9610 - val_loss: 4.1682\n",
      "Epoch 142/700\n",
      " - 47s - loss: 4.9216 - val_loss: 4.6665\n",
      "Epoch 143/700\n",
      " - 46s - loss: 4.9109 - val_loss: 4.1919\n",
      "Epoch 144/700\n",
      " - 46s - loss: 4.9577 - val_loss: 5.1102\n",
      "Epoch 145/700\n",
      " - 46s - loss: 5.0702 - val_loss: 4.1032\n",
      "Epoch 146/700\n",
      " - 47s - loss: 4.9552 - val_loss: 4.8875\n",
      "Epoch 147/700\n",
      " - 46s - loss: 4.9580 - val_loss: 4.3392\n",
      "Epoch 148/700\n",
      " - 46s - loss: 4.9077 - val_loss: 4.2855\n",
      "Epoch 149/700\n",
      " - 47s - loss: 4.8884 - val_loss: 4.7992\n",
      "Epoch 150/700\n",
      " - 47s - loss: 4.8688 - val_loss: 4.2817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/700\n",
      " - 46s - loss: 4.8733 - val_loss: 4.2141\n",
      "Epoch 152/700\n",
      " - 46s - loss: 4.8760 - val_loss: 4.7314\n",
      "Epoch 153/700\n",
      " - 47s - loss: 4.8898 - val_loss: 4.1044\n",
      "Epoch 154/700\n",
      " - 46s - loss: 4.9051 - val_loss: 4.7034\n",
      "Epoch 155/700\n",
      " - 46s - loss: 4.8765 - val_loss: 4.5337\n",
      "Epoch 156/700\n",
      " - 46s - loss: 4.8917 - val_loss: 4.1091\n",
      "Epoch 157/700\n",
      " - 46s - loss: 4.9240 - val_loss: 4.5149\n",
      "Epoch 158/700\n",
      " - 46s - loss: 4.8902 - val_loss: 4.7397\n",
      "Epoch 159/700\n",
      " - 46s - loss: 4.8792 - val_loss: 4.3269\n",
      "Epoch 160/700\n",
      " - 47s - loss: 4.8779 - val_loss: 4.9842\n",
      "Epoch 161/700\n",
      " - 46s - loss: 5.0267 - val_loss: 4.0460\n",
      "Epoch 162/700\n",
      " - 46s - loss: 5.0991 - val_loss: 4.5473\n",
      "Epoch 163/700\n",
      " - 46s - loss: 4.8467 - val_loss: 5.0089\n",
      "Epoch 164/700\n",
      " - 47s - loss: 4.9183 - val_loss: 4.1052\n",
      "Epoch 165/700\n",
      " - 47s - loss: 4.8657 - val_loss: 4.7201\n",
      "Epoch 166/700\n",
      " - 46s - loss: 4.8371 - val_loss: 4.1878\n",
      "Epoch 167/700\n",
      " - 47s - loss: 4.8718 - val_loss: 4.6812\n",
      "Epoch 168/700\n",
      " - 46s - loss: 4.8886 - val_loss: 4.1965\n",
      "Epoch 169/700\n",
      " - 46s - loss: 4.8212 - val_loss: 5.0943\n",
      "Epoch 170/700\n",
      " - 46s - loss: 4.9466 - val_loss: 4.0354\n",
      "Epoch 171/700\n",
      " - 46s - loss: 4.8864 - val_loss: 4.7055\n",
      "Epoch 172/700\n",
      " - 46s - loss: 4.8091 - val_loss: 4.1312\n",
      "Epoch 173/700\n",
      " - 46s - loss: 4.8407 - val_loss: 4.4002\n",
      "Epoch 174/700\n",
      " - 46s - loss: 4.7854 - val_loss: 4.3517\n",
      "Epoch 175/700\n",
      " - 46s - loss: 4.7874 - val_loss: 4.3853\n",
      "Epoch 176/700\n",
      " - 46s - loss: 4.8007 - val_loss: 4.8999\n",
      "Epoch 177/700\n",
      " - 46s - loss: 4.9049 - val_loss: 4.0550\n",
      "Epoch 178/700\n",
      " - 46s - loss: 4.8294 - val_loss: 5.2983\n",
      "Epoch 179/700\n",
      " - 46s - loss: 4.9351 - val_loss: 4.0218\n",
      "Epoch 180/700\n",
      " - 46s - loss: 4.9597 - val_loss: 4.8999\n",
      "Epoch 181/700\n",
      " - 46s - loss: 4.9126 - val_loss: 4.0577\n",
      "Epoch 182/700\n",
      " - 47s - loss: 5.0041 - val_loss: 4.9962\n",
      "Epoch 183/700\n",
      " - 47s - loss: 4.8737 - val_loss: 4.2017\n",
      "Epoch 184/700\n",
      " - 46s - loss: 4.8492 - val_loss: 4.5886\n",
      "Epoch 185/700\n",
      " - 46s - loss: 4.8482 - val_loss: 4.1494\n",
      "Epoch 186/700\n",
      " - 47s - loss: 4.9405 - val_loss: 4.4462\n",
      "Epoch 187/700\n",
      " - 46s - loss: 4.8921 - val_loss: 4.1652\n",
      "Epoch 188/700\n",
      " - 47s - loss: 4.7910 - val_loss: 4.6169\n",
      "Epoch 189/700\n",
      " - 47s - loss: 4.8115 - val_loss: 4.3242\n",
      "Epoch 190/700\n",
      " - 46s - loss: 4.7854 - val_loss: 4.2272\n",
      "Epoch 191/700\n",
      " - 46s - loss: 4.7992 - val_loss: 4.3027\n",
      "Epoch 192/700\n",
      " - 46s - loss: 4.7626 - val_loss: 4.3968\n",
      "Epoch 193/700\n",
      " - 46s - loss: 4.7712 - val_loss: 4.4530\n",
      "Epoch 194/700\n",
      " - 46s - loss: 4.7751 - val_loss: 4.5531\n",
      "Epoch 195/700\n",
      " - 46s - loss: 4.7677 - val_loss: 4.2740\n",
      "Epoch 196/700\n",
      " - 47s - loss: 4.7561 - val_loss: 4.4142\n",
      "Epoch 197/700\n",
      " - 47s - loss: 4.7737 - val_loss: 4.6798\n",
      "Epoch 198/700\n",
      " - 46s - loss: 4.8100 - val_loss: 4.2361\n",
      "Epoch 199/700\n",
      " - 46s - loss: 4.9113 - val_loss: 4.1514\n",
      "Epoch 200/700\n",
      " - 46s - loss: 4.8861 - val_loss: 4.5834\n",
      "Epoch 201/700\n",
      " - 46s - loss: 4.9534 - val_loss: 4.2362\n",
      "Epoch 202/700\n",
      " - 46s - loss: 4.9955 - val_loss: 4.7812\n",
      "Epoch 203/700\n",
      " - 46s - loss: 4.8735 - val_loss: 4.1670\n",
      "Epoch 204/700\n",
      " - 46s - loss: 4.9875 - val_loss: 4.9985\n",
      "Epoch 205/700\n",
      " - 46s - loss: 4.8670 - val_loss: 4.1093\n",
      "Epoch 206/700\n",
      " - 47s - loss: 4.7734 - val_loss: 4.2769\n",
      "Epoch 207/700\n",
      " - 47s - loss: 4.7480 - val_loss: 4.2480\n",
      "Epoch 208/700\n",
      " - 47s - loss: 4.7779 - val_loss: 4.5912\n",
      "Epoch 209/700\n",
      " - 46s - loss: 4.7741 - val_loss: 4.2150\n",
      "Epoch 210/700\n",
      " - 46s - loss: 4.7448 - val_loss: 4.3592\n",
      "Epoch 211/700\n",
      " - 47s - loss: 4.7460 - val_loss: 4.2541\n",
      "Epoch 212/700\n",
      " - 47s - loss: 4.7321 - val_loss: 4.2185\n",
      "Epoch 213/700\n",
      " - 46s - loss: 4.7300 - val_loss: 4.4213\n",
      "Epoch 214/700\n",
      " - 46s - loss: 4.7269 - val_loss: 4.5766\n",
      "Epoch 215/700\n",
      " - 46s - loss: 4.7376 - val_loss: 4.1164\n",
      "Epoch 216/700\n",
      " - 46s - loss: 4.7508 - val_loss: 4.6295\n",
      "Epoch 217/700\n",
      " - 46s - loss: 4.7645 - val_loss: 4.4323\n",
      "Epoch 218/700\n",
      " - 46s - loss: 4.7293 - val_loss: 4.5070\n",
      "Epoch 219/700\n",
      " - 46s - loss: 4.7295 - val_loss: 4.3773\n",
      "Epoch 220/700\n",
      " - 47s - loss: 4.7267 - val_loss: 4.0995\n",
      "Epoch 221/700\n",
      " - 46s - loss: 4.7977 - val_loss: 4.2736\n",
      "Epoch 222/700\n",
      " - 46s - loss: 4.8013 - val_loss: 4.8038\n",
      "Epoch 223/700\n",
      " - 47s - loss: 4.8094 - val_loss: 4.2505\n",
      "Epoch 224/700\n",
      " - 46s - loss: 4.7797 - val_loss: 4.4255\n",
      "Epoch 225/700\n",
      " - 46s - loss: 4.7194 - val_loss: 4.3381\n",
      "Epoch 226/700\n",
      " - 46s - loss: 4.7324 - val_loss: 4.4373\n",
      "Epoch 227/700\n",
      " - 46s - loss: 4.7159 - val_loss: 4.3524\n",
      "Epoch 228/700\n",
      " - 46s - loss: 4.7505 - val_loss: 4.2023\n",
      "Epoch 229/700\n",
      " - 47s - loss: 4.7313 - val_loss: 4.5342\n",
      "Epoch 230/700\n",
      " - 47s - loss: 4.7303 - val_loss: 4.2374\n",
      "Epoch 231/700\n",
      " - 46s - loss: 4.7188 - val_loss: 4.3326\n",
      "Epoch 232/700\n",
      " - 47s - loss: 4.7295 - val_loss: 4.5206\n",
      "Epoch 233/700\n",
      " - 46s - loss: 4.7676 - val_loss: 4.9070\n",
      "Epoch 234/700\n",
      " - 46s - loss: 4.8238 - val_loss: 4.0423\n",
      "Epoch 235/700\n",
      " - 47s - loss: 4.8657 - val_loss: 4.6765\n",
      "Epoch 236/700\n",
      " - 46s - loss: 4.7946 - val_loss: 4.3838\n",
      "Epoch 237/700\n",
      " - 46s - loss: 4.7678 - val_loss: 4.2376\n",
      "Epoch 238/700\n",
      " - 46s - loss: 4.7364 - val_loss: 4.7683\n",
      "Epoch 239/700\n",
      " - 46s - loss: 4.7830 - val_loss: 4.3224\n",
      "Epoch 240/700\n",
      " - 46s - loss: 4.7224 - val_loss: 4.2968\n",
      "Epoch 241/700\n",
      " - 46s - loss: 4.7061 - val_loss: 4.2753\n",
      "Epoch 242/700\n",
      " - 46s - loss: 4.7230 - val_loss: 4.0498\n",
      "Epoch 243/700\n",
      " - 47s - loss: 4.7587 - val_loss: 4.3348\n",
      "Epoch 244/700\n",
      " - 47s - loss: 4.7235 - val_loss: 4.7025\n",
      "Epoch 245/700\n",
      " - 46s - loss: 4.7244 - val_loss: 4.6108\n",
      "Epoch 246/700\n",
      " - 46s - loss: 4.7442 - val_loss: 4.5088\n",
      "Epoch 247/700\n",
      " - 47s - loss: 4.7496 - val_loss: 4.0824\n",
      "Epoch 248/700\n",
      " - 46s - loss: 4.7564 - val_loss: 4.8447\n",
      "Epoch 249/700\n",
      " - 46s - loss: 4.7441 - val_loss: 4.2475\n",
      "Epoch 250/700\n",
      " - 46s - loss: 4.7385 - val_loss: 4.1940\n",
      "Epoch 251/700\n",
      " - 47s - loss: 4.7430 - val_loss: 4.3812\n",
      "Epoch 252/700\n",
      " - 47s - loss: 4.6933 - val_loss: 4.1920\n",
      "Epoch 253/700\n",
      " - 46s - loss: 4.7054 - val_loss: 4.4792\n",
      "Epoch 254/700\n",
      " - 46s - loss: 4.7168 - val_loss: 4.4633\n",
      "Epoch 255/700\n",
      " - 46s - loss: 4.7215 - val_loss: 4.0615\n",
      "Epoch 256/700\n",
      " - 46s - loss: 4.7144 - val_loss: 4.2452\n",
      "Epoch 257/700\n",
      " - 46s - loss: 4.6912 - val_loss: 4.3588\n",
      "Epoch 258/700\n",
      " - 46s - loss: 4.6914 - val_loss: 4.0577\n",
      "Epoch 259/700\n",
      " - 47s - loss: 4.7419 - val_loss: 4.6900\n",
      "Epoch 260/700\n",
      " - 46s - loss: 4.6991 - val_loss: 3.9751\n",
      "Epoch 261/700\n",
      " - 46s - loss: 4.8167 - val_loss: 4.5684\n",
      "Epoch 262/700\n",
      " - 46s - loss: 4.8262 - val_loss: 4.4963\n",
      "Epoch 263/700\n",
      " - 46s - loss: 4.8561 - val_loss: 4.0583\n",
      "Epoch 264/700\n",
      " - 46s - loss: 4.7608 - val_loss: 4.7947\n",
      "Epoch 265/700\n",
      " - 46s - loss: 4.7835 - val_loss: 4.0604\n",
      "Epoch 266/700\n",
      " - 46s - loss: 4.7059 - val_loss: 4.0783\n",
      "Epoch 267/700\n",
      " - 46s - loss: 4.7126 - val_loss: 4.8836\n",
      "Epoch 268/700\n",
      " - 46s - loss: 4.7378 - val_loss: 4.0803\n",
      "Epoch 269/700\n",
      " - 46s - loss: 4.7466 - val_loss: 4.3799\n",
      "Epoch 270/700\n",
      " - 46s - loss: 4.7253 - val_loss: 4.6308\n",
      "Epoch 271/700\n",
      " - 47s - loss: 4.7124 - val_loss: 4.0604\n",
      "Epoch 272/700\n",
      " - 46s - loss: 4.8557 - val_loss: 4.2138\n",
      "Epoch 273/700\n",
      " - 46s - loss: 4.9255 - val_loss: 5.1461\n",
      "Epoch 274/700\n",
      " - 46s - loss: 4.9427 - val_loss: 3.9613\n",
      "Epoch 275/700\n",
      " - 47s - loss: 4.9311 - val_loss: 4.9748\n",
      "Epoch 276/700\n",
      " - 47s - loss: 4.7834 - val_loss: 3.9585\n",
      "Epoch 277/700\n",
      " - 47s - loss: 4.8127 - val_loss: 5.0591\n",
      "Epoch 278/700\n",
      " - 46s - loss: 4.8231 - val_loss: 3.9953\n",
      "Epoch 279/700\n",
      " - 46s - loss: 4.8050 - val_loss: 5.1487\n",
      "Epoch 280/700\n",
      " - 47s - loss: 4.8198 - val_loss: 4.0761\n",
      "Epoch 281/700\n",
      " - 47s - loss: 4.7252 - val_loss: 4.5775\n",
      "Epoch 282/700\n",
      " - 46s - loss: 4.7089 - val_loss: 4.0970\n",
      "Epoch 283/700\n",
      " - 46s - loss: 4.7185 - val_loss: 4.5563\n",
      "Epoch 284/700\n",
      " - 46s - loss: 4.7033 - val_loss: 4.1292\n",
      "Epoch 285/700\n",
      " - 47s - loss: 4.6841 - val_loss: 4.3298\n",
      "Epoch 286/700\n",
      " - 46s - loss: 4.7123 - val_loss: 4.2607\n",
      "Epoch 287/700\n",
      " - 46s - loss: 4.6776 - val_loss: 4.2405\n",
      "Epoch 288/700\n",
      " - 46s - loss: 4.7103 - val_loss: 4.0335\n",
      "Epoch 289/700\n",
      " - 46s - loss: 4.7627 - val_loss: 5.0345\n",
      "Epoch 290/700\n",
      " - 46s - loss: 4.7748 - val_loss: 3.9498\n",
      "Epoch 291/700\n",
      " - 46s - loss: 4.8089 - val_loss: 4.6662\n",
      "Epoch 292/700\n",
      " - 46s - loss: 4.7162 - val_loss: 3.9507\n",
      "Epoch 293/700\n",
      " - 47s - loss: 4.7812 - val_loss: 4.6665\n",
      "Epoch 294/700\n",
      " - 46s - loss: 4.8131 - val_loss: 4.0573\n",
      "Epoch 295/700\n",
      " - 46s - loss: 4.7997 - val_loss: 4.7175\n",
      "Epoch 296/700\n",
      " - 47s - loss: 4.7475 - val_loss: 4.0049\n",
      "Epoch 297/700\n",
      " - 46s - loss: 4.7712 - val_loss: 4.4325\n",
      "Epoch 298/700\n",
      " - 46s - loss: 4.6839 - val_loss: 4.5585\n",
      "Epoch 299/700\n",
      " - 46s - loss: 4.6906 - val_loss: 4.0481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/700\n",
      " - 46s - loss: 4.7440 - val_loss: 4.6928\n",
      "Epoch 301/700\n",
      " - 46s - loss: 4.7666 - val_loss: 4.2849\n",
      "Epoch 302/700\n",
      " - 47s - loss: 4.7186 - val_loss: 4.0888\n",
      "Epoch 303/700\n",
      " - 46s - loss: 4.7044 - val_loss: 4.9240\n",
      "Epoch 304/700\n",
      " - 47s - loss: 4.7396 - val_loss: 4.0893\n",
      "Epoch 305/700\n",
      " - 46s - loss: 4.6814 - val_loss: 4.3994\n",
      "Epoch 306/700\n",
      " - 46s - loss: 4.6865 - val_loss: 4.2288\n",
      "Epoch 307/700\n",
      " - 46s - loss: 4.6745 - val_loss: 4.1865\n",
      "Epoch 308/700\n",
      " - 46s - loss: 4.6699 - val_loss: 4.2432\n",
      "Epoch 309/700\n",
      " - 46s - loss: 4.7208 - val_loss: 4.2784\n",
      "Epoch 310/700\n",
      " - 46s - loss: 4.6662 - val_loss: 4.3595\n",
      "Epoch 311/700\n",
      " - 46s - loss: 4.6668 - val_loss: 4.2686\n",
      "Epoch 312/700\n",
      " - 46s - loss: 4.6743 - val_loss: 4.0257\n",
      "Epoch 313/700\n",
      " - 46s - loss: 4.7414 - val_loss: 4.8866\n",
      "Epoch 314/700\n",
      " - 46s - loss: 4.8916 - val_loss: 3.9526\n",
      "Epoch 315/700\n",
      " - 46s - loss: 4.9169 - val_loss: 5.0764\n",
      "Epoch 316/700\n",
      " - 47s - loss: 4.7977 - val_loss: 4.0950\n",
      "Epoch 317/700\n",
      " - 46s - loss: 4.7321 - val_loss: 4.0154\n",
      "Epoch 318/700\n",
      " - 46s - loss: 4.7028 - val_loss: 4.4665\n",
      "Epoch 319/700\n",
      " - 47s - loss: 4.6990 - val_loss: 3.9981\n",
      "Epoch 320/700\n",
      " - 46s - loss: 4.6973 - val_loss: 4.4643\n",
      "Epoch 321/700\n",
      " - 47s - loss: 4.6751 - val_loss: 4.2868\n",
      "Epoch 322/700\n",
      " - 46s - loss: 4.6713 - val_loss: 4.3180\n",
      "Epoch 323/700\n",
      " - 46s - loss: 4.6808 - val_loss: 4.2504\n",
      "Epoch 324/700\n",
      " - 46s - loss: 4.7174 - val_loss: 4.1049\n",
      "Epoch 325/700\n",
      " - 46s - loss: 4.6825 - val_loss: 4.4904\n",
      "Epoch 326/700\n",
      " - 46s - loss: 4.7891 - val_loss: 3.9352\n",
      "Epoch 327/700\n",
      " - 46s - loss: 4.8865 - val_loss: 4.9125\n",
      "Epoch 328/700\n",
      " - 46s - loss: 4.7688 - val_loss: 3.9327\n",
      "Epoch 329/700\n",
      " - 46s - loss: 4.8271 - val_loss: 5.3449\n",
      "Epoch 330/700\n",
      " - 46s - loss: 4.9461 - val_loss: 3.9963\n",
      "Epoch 331/700\n",
      " - 47s - loss: 4.8705 - val_loss: 5.1509\n",
      "Epoch 332/700\n",
      " - 47s - loss: 4.7565 - val_loss: 3.9633\n",
      "Epoch 333/700\n",
      " - 46s - loss: 4.7339 - val_loss: 4.5673\n",
      "Epoch 334/700\n",
      " - 46s - loss: 4.7306 - val_loss: 3.9954\n",
      "Epoch 335/700\n",
      " - 46s - loss: 4.7023 - val_loss: 4.6230\n",
      "Epoch 336/700\n",
      " - 46s - loss: 4.7140 - val_loss: 4.0391\n",
      "Epoch 337/700\n",
      " - 46s - loss: 4.6764 - val_loss: 4.3837\n",
      "Epoch 338/700\n",
      " - 46s - loss: 4.6516 - val_loss: 4.0129\n",
      "Epoch 339/700\n",
      " - 46s - loss: 4.6975 - val_loss: 4.7143\n",
      "Epoch 340/700\n",
      " - 46s - loss: 4.7391 - val_loss: 3.9406\n",
      "Epoch 341/700\n",
      " - 46s - loss: 4.7907 - val_loss: 4.8956\n",
      "Epoch 342/700\n",
      " - 46s - loss: 4.7773 - val_loss: 4.0549\n",
      "Epoch 343/700\n",
      " - 46s - loss: 4.7001 - val_loss: 4.6167\n",
      "Epoch 344/700\n",
      " - 46s - loss: 4.7102 - val_loss: 3.9623\n",
      "Epoch 345/700\n",
      " - 46s - loss: 4.7340 - val_loss: 4.5429\n",
      "Epoch 346/700\n",
      " - 46s - loss: 4.6625 - val_loss: 3.9736\n",
      "Epoch 347/700\n",
      " - 46s - loss: 4.7584 - val_loss: 4.6591\n",
      "Epoch 348/700\n",
      " - 46s - loss: 4.7409 - val_loss: 3.9736\n",
      "Epoch 349/700\n",
      " - 47s - loss: 4.7080 - val_loss: 4.2749\n",
      "Epoch 350/700\n",
      " - 46s - loss: 4.6639 - val_loss: 4.1617\n",
      "Epoch 351/700\n",
      " - 47s - loss: 4.6636 - val_loss: 4.1352\n",
      "Epoch 352/700\n",
      " - 46s - loss: 4.6872 - val_loss: 4.0612\n",
      "Epoch 353/700\n",
      " - 46s - loss: 4.6722 - val_loss: 4.2564\n",
      "Epoch 354/700\n",
      " - 46s - loss: 4.6619 - val_loss: 4.3258\n",
      "Epoch 355/700\n",
      " - 47s - loss: 4.6894 - val_loss: 4.2280\n",
      "Epoch 356/700\n",
      " - 46s - loss: 4.6439 - val_loss: 4.5414\n",
      "Epoch 357/700\n",
      " - 47s - loss: 4.6547 - val_loss: 4.2271\n",
      "Epoch 358/700\n",
      " - 46s - loss: 4.6868 - val_loss: 4.3571\n",
      "Epoch 359/700\n",
      " - 46s - loss: 4.7330 - val_loss: 4.0771\n",
      "Epoch 360/700\n",
      " - 46s - loss: 4.7825 - val_loss: 4.4745\n",
      "Epoch 361/700\n",
      " - 47s - loss: 4.7341 - val_loss: 4.7820\n",
      "Epoch 362/700\n",
      " - 46s - loss: 4.7540 - val_loss: 4.1152\n",
      "Epoch 363/700\n",
      " - 46s - loss: 4.6480 - val_loss: 4.2223\n",
      "Epoch 364/700\n",
      " - 46s - loss: 4.6519 - val_loss: 3.9557\n",
      "Epoch 365/700\n",
      " - 46s - loss: 4.6944 - val_loss: 4.4803\n",
      "Epoch 366/700\n",
      " - 46s - loss: 4.7185 - val_loss: 4.2127\n",
      "Epoch 367/700\n",
      " - 46s - loss: 4.7962 - val_loss: 3.9615\n",
      "Epoch 368/700\n",
      " - 46s - loss: 4.7206 - val_loss: 4.4405\n",
      "Epoch 369/700\n",
      " - 47s - loss: 4.6728 - val_loss: 4.1009\n",
      "Epoch 370/700\n",
      " - 46s - loss: 4.7393 - val_loss: 4.5149\n",
      "Epoch 371/700\n",
      " - 46s - loss: 4.7203 - val_loss: 4.2586\n",
      "Epoch 372/700\n",
      " - 46s - loss: 4.6614 - val_loss: 4.1474\n",
      "Epoch 373/700\n",
      " - 46s - loss: 4.6495 - val_loss: 4.1921\n",
      "Epoch 374/700\n",
      " - 46s - loss: 4.6518 - val_loss: 4.3466\n",
      "Epoch 375/700\n",
      " - 46s - loss: 4.6572 - val_loss: 4.0095\n",
      "Epoch 376/700\n",
      " - 46s - loss: 4.7326 - val_loss: 5.0043\n",
      "Epoch 377/700\n",
      " - 47s - loss: 4.7949 - val_loss: 3.9324\n",
      "Epoch 378/700\n",
      " - 46s - loss: 4.6843 - val_loss: 4.0971\n",
      "Epoch 379/700\n",
      " - 46s - loss: 4.6737 - val_loss: 4.0784\n",
      "Epoch 380/700\n",
      " - 46s - loss: 4.6730 - val_loss: 4.2224\n",
      "Epoch 381/700\n",
      " - 46s - loss: 4.6465 - val_loss: 4.2055\n",
      "Epoch 382/700\n",
      " - 46s - loss: 4.6482 - val_loss: 4.4060\n",
      "Epoch 383/700\n",
      " - 47s - loss: 4.6836 - val_loss: 4.1153\n",
      "Epoch 384/700\n",
      " - 46s - loss: 4.6493 - val_loss: 4.3267\n",
      "Epoch 385/700\n",
      " - 46s - loss: 4.6505 - val_loss: 4.1387\n",
      "Epoch 386/700\n",
      " - 46s - loss: 4.7098 - val_loss: 4.3321\n",
      "Epoch 387/700\n",
      " - 46s - loss: 4.7661 - val_loss: 4.0871\n",
      "Epoch 388/700\n",
      " - 46s - loss: 4.7566 - val_loss: 4.3334\n",
      "Epoch 389/700\n",
      " - 46s - loss: 4.6987 - val_loss: 4.2342\n",
      "Epoch 390/700\n",
      " - 46s - loss: 4.6992 - val_loss: 4.1669\n",
      "Epoch 391/700\n",
      " - 46s - loss: 4.6560 - val_loss: 4.4134\n",
      "Epoch 392/700\n",
      " - 46s - loss: 4.7320 - val_loss: 3.9100\n",
      "Epoch 393/700\n",
      " - 46s - loss: 4.8879 - val_loss: 4.9168\n",
      "Epoch 394/700\n",
      " - 47s - loss: 4.8846 - val_loss: 3.9218\n",
      "Epoch 395/700\n",
      " - 48s - loss: 4.8826 - val_loss: 5.1512\n",
      "Epoch 396/700\n",
      " - 47s - loss: 5.1124 - val_loss: 4.2501\n",
      "Epoch 397/700\n",
      " - 47s - loss: 5.0395 - val_loss: 3.9843\n",
      "Epoch 398/700\n",
      " - 48s - loss: 4.7807 - val_loss: 4.9585\n",
      "Epoch 399/700\n",
      " - 47s - loss: 4.7289 - val_loss: 3.9231\n",
      "Epoch 400/700\n",
      " - 48s - loss: 4.7888 - val_loss: 4.7145\n",
      "Epoch 401/700\n",
      " - 48s - loss: 4.8149 - val_loss: 3.9094\n",
      "Epoch 402/700\n",
      " - 47s - loss: 4.8224 - val_loss: 4.4998\n",
      "Epoch 403/700\n",
      " - 48s - loss: 4.6620 - val_loss: 4.1123\n",
      "Epoch 404/700\n",
      " - 48s - loss: 4.6802 - val_loss: 4.4097\n",
      "Epoch 405/700\n",
      " - 48s - loss: 4.7039 - val_loss: 3.9419\n",
      "Epoch 406/700\n",
      " - 48s - loss: 4.6905 - val_loss: 4.5844\n"
     ]
    }
   ],
   "source": [
    "modelConvLSTM = Sequential()\n",
    "modelConvLSTM.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', return_sequences=True,input_shape=(X_train.shape[1], 1, X_train.shape[3], X_train.shape[4])))\n",
    "modelConvLSTM.add(ConvLSTM2D(filters=32, kernel_size=(1,2), activation='relu'))\n",
    "modelConvLSTM.add(Flatten())\n",
    "modelConvLSTM.add(Dense(64))\n",
    "modelConvLSTM.add(Dense(32))\n",
    "modelConvLSTM.add(Dense(1))\n",
    "modelConvLSTM.compile(optimizer='adam', loss='huber_loss')\n",
    "history = modelConvLSTM.fit(X_train, y_train, batch_size=512, epochs=700, verbose=2, callbacks=[early_stop], validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Explained Variance Score': 0.6681566977322875,\n",
       " 'Max Error': 43.57510864257813,\n",
       " 'Mean Absolute Error': 5.071442193500067,\n",
       " 'Mean Squared Error': 45.701804261837204,\n",
       " 'Root Mean Squared Error': 6.760310958960187,\n",
       " 'Median Absolute Error': 4.331775360107422,\n",
       " 'R² Score': 0.653021377756974,\n",
       " 'Mean Absolute Percentage Error': 5.048727175214505}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvLSTMpred = modelConvLSTM.predict(X_valid, verbose=0)\n",
    "ConvLSTMpred = ConvLSTMpred.reshape((ConvLSTMpred.shape[0]))\n",
    "ConvLSTMresults = metrics(ConvLSTMpred, y_valid)\n",
    "ConvLSTMresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvLSTMpred = modelConvLSTM.predict(X_test, verbose=0)\n",
    "ConvLSTMpred = ConvLSTMpred.reshape((ConvLSTMpred.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 78.36369 ,  90.270706,  77.05674 , ...,  94.3286  , 110.587555,\n",
       "        93.061295], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvLSTMpred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
